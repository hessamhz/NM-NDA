{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Homework**\n",
        "\n",
        "Complete the following tasks:\n",
        "\n",
        "* Use a dataset of 21 Video Sessions\n",
        "* Recognize the Video Server(s) IP and select video traffic (***if more than one Server is found, keep the dominant flow only***)\n",
        "* Detect Video Client HTTP Requests (Uplink packets with size larger or equal to 100 Bytes)\n",
        "* Compute features to predict:\n",
        " 1.   When the next UL Request is sent by the Video Client \n",
        " 2.   How large is the response of the Server to the next UL Request\n",
        "\n",
        "**N.B.**: Below, you can find a list of useful functions for the tasks at hand (introduced during class)."
      ],
      "metadata": {
        "id": "EgRb4mQBd2UY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zJxa-o59dwkB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions Ready-To-Use"
      ],
      "metadata": {
        "id": "7DsJgewH_DVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_traffic(data, domain):\n",
        "   \n",
        "    # Look in DNS Responses for googlevideo domain\n",
        "    dns_data = data[data['Protocol']=='DNS']\n",
        "    dns = dns_data[dns_data['Info'].apply(lambda x: 'googlevideo' in x and 'response' in x)]\n",
        "    ips = dns.Address.values \n",
        "    server_names = dns.Name.values\n",
        "    \n",
        "    # Filtering on either \"Source\" or \"Destination\" IP, get the \n",
        "    # rows of the dataset that contain at least one of the selected IPs\n",
        "    downlink = data[data['Source'].apply(lambda x: x in ips)].dropna(subset=['Length']) \n",
        "\n",
        "    uplink = data[data['Destination'].apply(lambda x: x in ips)].dropna(subset=['Length'])\n",
        "    \n",
        "    return ips, server_names, uplink, downlink\n",
        "\n",
        "def find_dominant(uplink, downlink):\n",
        "\n",
        "  # Expressed in MB\n",
        "\n",
        "  # Order flows by cumulative DL Volume\n",
        "  flows_DL = downlink.groupby(['Source','Destination'])['Length'].sum()/(10**6)\n",
        "  # print(flows_DL)\n",
        "  \n",
        "  # Get (Source,Destination) IPs of dominant flows\n",
        "  dom_id = flows_DL[flows_DL==max(flows_DL)].index[0]\n",
        "  # ('91.81.217.140', '192.168.1.6')\n",
        "  # Edited this\n",
        "  # Filter traffic selecting the dominant flow\n",
        "  dom_dl = downlink[downlink['Source']==dom_id[0]]\n",
        "  dom_ul = uplink[(uplink['Destination']==dom_id[0])]\n",
        "\n",
        "  return dom_ul, dom_dl\n",
        "\n",
        "def timebased_filter(data, length=None, min_time=None, max_time=None):\n",
        "  '''\n",
        "  :param data: pd dataframe to be filtered. Must contain columns: \"Length\" and \"Time\"\n",
        "  :param length: all packets shorter than length [Bytes] will be discarded (default 0)\n",
        "  :param min_time: all packets with timestamp smaller than min_time [s] will be discarded (default 0)\n",
        "  :param max_time: all packets with timestamp larger than max_time [s] will be discarded (default 1000)\n",
        "  '''\n",
        "\n",
        "  if length is None:\n",
        "    length=0\n",
        "  if min_time is None:\n",
        "    min_time = 0\n",
        "  if max_time is None:\n",
        "    max_time = 1000\n",
        "  \n",
        "  filtered_data = data.copy().reset_index()\n",
        "  mask = (filtered_data['Length']>=length) & (filtered_data['Time']>=min_time) & (filtered_data['Time']<= max_time)\n",
        "  filtered_data = filtered_data.loc[mask[mask ==True].index]\n",
        "\n",
        "  return filtered_data\n",
        "\n",
        "def find_next(array, value):\n",
        "  '''\n",
        "  :param array: np.array, array of floats\n",
        "  :param value: float, reference value\n",
        "  :return: position of the closest element of the array greater than \"value\"\n",
        "  '''\n",
        "  delta = np.asarray(array) - value\n",
        "  idx = np.where(delta >= 0, delta, np.inf).argmin()\n",
        "\n",
        "  return idx\n",
        "\n",
        "def normalize_dataset(training_set, test_set):\n",
        "\n",
        "  mean_train = training_set.mean()\n",
        "  std_train = training_set.std()\n",
        "  norm_train = (training_set - mean_train)/std_train\n",
        "  norm_test = (test_set - mean_train)/std_train  \n",
        "\n",
        "  return norm_train, norm_test"
      ],
      "metadata": {
        "id": "-EKk7Xqfd6gI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions to be completed\n"
      ],
      "metadata": {
        "id": "jMO_nFab_IPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def features_extraction(uplink, downlink):\n",
        "  '''\n",
        "  Complete this function to extract both features and groundtruth.\n",
        "\n",
        "  NB: The features extraction process is the same as the one introduced during\n",
        "  the lecture. \n",
        "  '''\n",
        "  dataset = pd.DataFrame(columns=['Request_Size','Inter_RR_Time','DL_Time','DL_Vol','DL_Size','PB_Time'])\n",
        "  # ****************************************************************************\n",
        "  # Feature 1: Client Request Size\n",
        "  dataset['Request_Size'] = list(uplink.Length.values)\n",
        "\n",
        "  # ****************************************************************************\n",
        "  # Feature 2: Inter Request-Response Time\n",
        "  rr_time = []\n",
        "  response_time = []\n",
        "  for t in uplink.Time:\n",
        "    response_time.append(find_next(downlink.Time, t)) #index of next DL packet timestamp \n",
        "    rr_time.append(downlink.Time.iloc[response_time[-1]] - t)\n",
        "\n",
        "  dataset['Inter_RR_Time'] = rr_time\n",
        "  # ****************************************************************************\n",
        "  # Feature 3-4-5: Download Time, Download Volume, Download Size (# Packets) \n",
        "  dt = []\n",
        "  dv = []\n",
        "  ds = []\n",
        "\n",
        "  for rt1, rt2 in zip(response_time[:-1], response_time[1:]):\n",
        "    #Download Time\n",
        "    dt.append(downlink.Time.iloc[rt2-1] - downlink.Time.iloc[rt1])\n",
        "\n",
        "    temp = timebased_filter(downlink, 0, downlink.Time.iloc[rt1], downlink.Time.iloc[rt2-1])\n",
        "    \n",
        "    #Download Volume\n",
        "    dv.append(temp.Length.sum())\n",
        "\n",
        "    #Download Size (# Packets) \n",
        "    ds.append(temp.shape[0])\n",
        "\n",
        "  # Last Iteration data might be corrupted due to drastic interruption of capture \n",
        "  # process. If it is so, an error would occur during the features extraction.\n",
        "  # To avoid this, we skip last HTTP iteration data when an error is raised \n",
        "  # using the try-except logic below.\n",
        "  try:\n",
        "    # Consider also last HTTP iteration\n",
        "    #Download Time\n",
        "    dt.append(downlink.Time.iloc[-1] - downlink.Time.iloc[rt2])\n",
        "\n",
        "    temp = timebased_filter(downlink, 0, downlink.Time.iloc[rt2], downlink.Time.iloc[-1])\n",
        "    #Download Volume\n",
        "    dv.append(temp.Length.sum())\n",
        "\n",
        "    #Download Size (# Packets) \n",
        "    ds.append(temp.shape[0])\n",
        "  except:\n",
        "    print(\"exception\")\n",
        "\n",
        "  dataset['DL_Time'] = dt\n",
        "  dataset['DL_Vol'] = dv\n",
        "  dataset['DL_Size'] = ds\n",
        "  \n",
        "\n",
        "  # ****************************************************************************\n",
        "  # Feature 5: Playback Time\n",
        "  pbt = list(uplink.Time.values)\n",
        "  dataset['PB_Time'] = pbt\n",
        "  # ****************************************************************************\n",
        "  \n",
        "  \n",
        "  # Check Features Consistency\n",
        "  #dataset = dataset[(dataset > 0).all(1)]\n",
        "  #dataset = dataset[dataset['DL_Time']<20]\n",
        "\n",
        "  ###############################################################\n",
        "  # TO BE COMPLETED\n",
        "\n",
        "  ### EXTRACT GROUNDTRUTH HERE\n",
        "  groundtruth = pd.DataFrame(columns=['Next_Request_Time','Next_Response_Vol'])\n",
        "  # ****************************************************************************\n",
        "  # GT 1: Next Request Time\n",
        "\n",
        "  # Filtering uplink requests which are more than 100bytes\n",
        "  uplink_reqs = uplink.copy().reset_index()\n",
        "  next_req_list = [None]\n",
        "  next_resp_vol = [None]\n",
        "  # We start from the 2nd uplink\n",
        "  for index, uplink_req in uplink_reqs.iloc[1:-1].iterrows():\n",
        "    # Finding the inter-request time \n",
        "    sub_dl = downlink[downlink[\"Time\"] < uplink_req[\"Time\"]]\n",
        "    # find the row with the closest value to x in the Time column\n",
        "    closest_row = sub_dl.iloc[(sub_dl['Time'] - uplink_req[\"Time\"]).abs().argsort()[:1]]\n",
        "    if not len(closest_row):\n",
        "      next_req_list.append(None)\n",
        "      next_resp_vol.append(None)\n",
        "      continue\n",
        "    delta = uplink_req.Time - closest_row.Time\n",
        "    next_req_list.append(delta.iloc[0])\n",
        "\n",
        "    # Calculating the Volume transfered in this timespan\n",
        "    sub_dl = downlink[\n",
        "                (downlink[\"Time\"] < uplink_reqs.iloc[index + 1].Time) &\n",
        "                (downlink[\"Time\"] > uplink_req.Time)\n",
        "    ]\n",
        "    next_resp_vol.append(sub_dl.Length.sum())\n",
        "  \n",
        "\n",
        "  next_req_list.append(None)\n",
        "  next_resp_vol.append(None)\n",
        "\n",
        "  #next_req_list.append(None)\n",
        "  #next_resp_vol.append(None)\n",
        "  \n",
        "  # print(next_req_list[0])\n",
        "  #groundtruth['Next_Request_Time'] = next_req_list\n",
        "  dataset['Next_Request_Time'] = next_req_list \n",
        "  # ****************************************************************************\n",
        "  # GT 2: Next Response Volume\n",
        "  \n",
        "  #groundtruth['Next_Response_Vol'] = next_resp_vol\n",
        "  dataset['Next_Response_Vol'] = next_resp_vol\n",
        "  ###############################################################\n",
        "\n",
        "\n",
        "  # I have made a little different approach with the proposed way.\n",
        "  # Check Features Consistency\n",
        "  dataset = dataset[(dataset > 0).all(1)]\n",
        "  dataset = dataset[dataset['DL_Time']<20]\n",
        "  dataset = dataset[dataset[\"Next_Response_Vol\"] > 0]\n",
        "  dataset['Next_Response_Vol'] = dataset['Next_Response_Vol'].shift(-1)\n",
        "  dataset.dropna(inplace=True)\n",
        "\n",
        "  groundtruth = dataset.loc[:, [\"Next_Request_Time\", \"Next_Response_Vol\"]]\n",
        "  dataset = dataset.loc[:, [\"Request_Size\", \"Inter_RR_Time\", \"DL_Time\", \"DL_Vol\", \"DL_Size\", \"PB_Time\"]]\n",
        "  \n",
        "\n",
        "  return dataset, groundtruth"
      ],
      "metadata": {
        "id": "Fi212kIMeIXr"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write your code here\n",
        "\n"
      ],
      "metadata": {
        "id": "d45P-M-v_PKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### First approach\n",
        "\n",
        "In This method we are using the provided functions to do the work. "
      ],
      "metadata": {
        "id": "xbn9IY0z-NKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joint_dataset = pd.DataFrame()\n",
        "joint_gt = pd.DataFrame()\n",
        "for i in range(22):\n",
        "  # Iterating through files\n",
        "  filename = f\"Capture_v2_{i}.csv\"\n",
        "  df = pd.read_csv(filename)\n",
        "  ips, server_names, uplink, downlink = filter_traffic(df, \"domain\")\n",
        "  dom_ul, dom_dl = find_dominant(uplink, downlink)\n",
        "  # Filtering the uplink and downlinks\n",
        "  # 100 bytes for uplink that comes from the paper\n",
        "  # 50 bytes for downlink that comes from the class discussion\n",
        "  dom_ul = timebased_filter(dom_ul, 100, 2, 180)\n",
        "  dom_dl = timebased_filter(dom_dl, 50, 2, 180)\n",
        "  dataset, groundtruth = features_extraction(dom_ul, dom_dl)\n",
        "  joint_dataset = pd.concat([joint_dataset, dataset])\n",
        "  joint_gt = pd.concat([joint_gt, groundtruth])\n",
        "  print(f\"i: {i}, dataset_shape: {dataset.shape[0]}\")\n",
        "  "
      ],
      "metadata": {
        "id": "4prKO9dxf_pB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b21c096-2823-4f3c-9a50-ab3ebfeefc50"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i: 0, dataset_shape: 45\n",
            "i: 1, dataset_shape: 40\n",
            "i: 2, dataset_shape: 35\n",
            "exception\n",
            "i: 3, dataset_shape: 0\n",
            "i: 4, dataset_shape: 23\n",
            "i: 5, dataset_shape: 7\n",
            "i: 6, dataset_shape: 5\n",
            "i: 7, dataset_shape: 74\n",
            "i: 8, dataset_shape: 16\n",
            "i: 9, dataset_shape: 4\n",
            "i: 10, dataset_shape: 3\n",
            "i: 11, dataset_shape: 3\n",
            "i: 12, dataset_shape: 7\n",
            "i: 13, dataset_shape: 3\n",
            "i: 14, dataset_shape: 10\n",
            "i: 15, dataset_shape: 0\n",
            "i: 16, dataset_shape: 10\n",
            "i: 17, dataset_shape: 4\n",
            "i: 18, dataset_shape: 6\n",
            "i: 19, dataset_shape: 0\n",
            "i: 20, dataset_shape: 5\n",
            "i: 21, dataset_shape: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we see there are some files that the dominant flow and ip wasn't identified properly. in order to tackle this issue we do something in the next part. \n"
      ],
      "metadata": {
        "id": "nGG9_IWP_RVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = joint_dataset\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "GV7CEBSIiV_e",
        "outputId": "8f937ea0-0bb8-4b77-b36c-7586ee887aab"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Request_Size  Inter_RR_Time   DL_Time    DL_Vol  DL_Size     PB_Time\n",
              "1          583.0       0.004833  0.005944   10602.0     10.0   16.448505\n",
              "5         1034.0       0.017107  0.000008    1592.0      6.0   16.474616\n",
              "7          654.0       0.009883  0.002476   23100.0     17.0   19.934595\n",
              "11         562.0       0.002912  0.055167   70024.0     49.0   24.182383\n",
              "13         565.0       0.003601  0.004896   69926.0     48.0   24.251007\n",
              "..           ...            ...       ...       ...      ...         ...\n",
              "1          583.0       0.004400  0.003151   11018.0     10.0   89.967206\n",
              "7          594.0       0.004044  0.054542  141656.0    100.0   89.976745\n",
              "9          602.0       0.004542  0.115750   71872.0     50.0   90.044470\n",
              "11         604.0       0.011249  0.012611  435428.0    298.0   97.324990\n",
              "13         686.0       0.010952  0.015277  513678.0    351.0  103.348191\n",
              "\n",
              "[305 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b9ac89d-4010-4e95-bf31-136198155744\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Request_Size</th>\n",
              "      <th>Inter_RR_Time</th>\n",
              "      <th>DL_Time</th>\n",
              "      <th>DL_Vol</th>\n",
              "      <th>DL_Size</th>\n",
              "      <th>PB_Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>583.0</td>\n",
              "      <td>0.004833</td>\n",
              "      <td>0.005944</td>\n",
              "      <td>10602.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>16.448505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1034.0</td>\n",
              "      <td>0.017107</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>1592.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>16.474616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>654.0</td>\n",
              "      <td>0.009883</td>\n",
              "      <td>0.002476</td>\n",
              "      <td>23100.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>19.934595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>562.0</td>\n",
              "      <td>0.002912</td>\n",
              "      <td>0.055167</td>\n",
              "      <td>70024.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>24.182383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>565.0</td>\n",
              "      <td>0.003601</td>\n",
              "      <td>0.004896</td>\n",
              "      <td>69926.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>24.251007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>583.0</td>\n",
              "      <td>0.004400</td>\n",
              "      <td>0.003151</td>\n",
              "      <td>11018.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>89.967206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>594.0</td>\n",
              "      <td>0.004044</td>\n",
              "      <td>0.054542</td>\n",
              "      <td>141656.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>89.976745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>602.0</td>\n",
              "      <td>0.004542</td>\n",
              "      <td>0.115750</td>\n",
              "      <td>71872.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>90.044470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>604.0</td>\n",
              "      <td>0.011249</td>\n",
              "      <td>0.012611</td>\n",
              "      <td>435428.0</td>\n",
              "      <td>298.0</td>\n",
              "      <td>97.324990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>686.0</td>\n",
              "      <td>0.010952</td>\n",
              "      <td>0.015277</td>\n",
              "      <td>513678.0</td>\n",
              "      <td>351.0</td>\n",
              "      <td>103.348191</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>305 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b9ac89d-4010-4e95-bf31-136198155744')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b9ac89d-4010-4e95-bf31-136198155744 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b9ac89d-4010-4e95-bf31-136198155744');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groundtruth = joint_gt \n",
        "groundtruth"
      ],
      "metadata": {
        "id": "Hk4uDp7Al-QX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "3738392b-5487-4104-deac-a38df3f809cd"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Next_Request_Time  Next_Response_Vol\n",
              "1            0.000999             1592.0\n",
              "5            0.015334            23100.0\n",
              "7            3.442864            70024.0\n",
              "11           4.235429            69926.0\n",
              "13           0.010545           145450.0\n",
              "..                ...                ...\n",
              "1            0.000181           141656.0\n",
              "7            0.001988            71872.0\n",
              "9            0.009139           435428.0\n",
              "11           7.160228           513678.0\n",
              "13           5.999341           512787.0\n",
              "\n",
              "[305 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd86fa86-a6b5-41d7-b49c-b66a7eee5a76\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Next_Request_Time</th>\n",
              "      <th>Next_Response_Vol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000999</td>\n",
              "      <td>1592.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.015334</td>\n",
              "      <td>23100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3.442864</td>\n",
              "      <td>70024.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4.235429</td>\n",
              "      <td>69926.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.010545</td>\n",
              "      <td>145450.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000181</td>\n",
              "      <td>141656.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.001988</td>\n",
              "      <td>71872.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.009139</td>\n",
              "      <td>435428.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>7.160228</td>\n",
              "      <td>513678.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>5.999341</td>\n",
              "      <td>512787.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>305 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd86fa86-a6b5-41d7-b49c-b66a7eee5a76')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd86fa86-a6b5-41d7-b49c-b66a7eee5a76 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd86fa86-a6b5-41d7-b49c-b66a7eee5a76');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we are working with random forest and it is a tree based model, there is little difference in using normalization for our data. "
      ],
      "metadata": {
        "id": "Q5B_JdJ_Tqzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_forest_regressor(X_train, X_test, y_train, y_test):\n",
        "  # Define the random forest regressor model\n",
        "  rf = RandomForestRegressor()\n",
        "\n",
        "  # Train the model on the training set\n",
        "  rf.fit(X_train, y_train)\n",
        "\n",
        "  # Use the trained model to make predictions on the test set\n",
        "  y_pred = rf.predict(X_test)\n",
        "\n",
        "  # Calculate the RMSE for this fold and add it to the list\n",
        "  return np.sqrt(mean_squared_error(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "6wkEZ74bIXF4"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kfold_test(dataset, groundtruth, n_folds):\n",
        "  kf = KFold(n_splits=n_folds)\n",
        "\n",
        "  # Initialize a list to store the RMSE scores for each fold\n",
        "  rmse_scores = []\n",
        "\n",
        "  # Iterate over the folds and train/test the model\n",
        "  for train_index, test_index in kf.split(X):\n",
        "    # Split the data into training and test sets for this fold\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Calculate the RMSE for this fold and add it to the list\n",
        "    rmse_scores.append(random_forest_regressor(X_train, X_test, y_train, y_test))\n",
        "\n",
        "  # Calculate the overall RMSE across all folds\n",
        "  mean_rmse = np.mean(rmse_scores)\n",
        "\n",
        "  return mean_rmse"
      ],
      "metadata": {
        "id": "sSuwDsL6Q2gv"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting X and y\n",
        "X = dataset.values\n",
        "y = groundtruth[\"Next_Request_Time\"].values.ravel()\n",
        "\n",
        "mean_rmse = kfold_test(dataset, groundtruth, 5)\n",
        "\n",
        "print('RMSE(in seconds):', mean_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM6oJJ_oyWn5",
        "outputId": "80ff7d2f-a115-403d-8495-11c24ef96f02"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE(in seconds): 5.0966306038378715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your data into X and y\n",
        "X = dataset.values\n",
        "y = groundtruth[\"Next_Response_Vol\"].values.ravel()\n",
        "\n",
        "mean_rmse = kfold_test(dataset, groundtruth, 5)\n",
        "\n",
        "# Since it's in kB we divide it by 1000\n",
        "print('RMSE(in kB):', mean_rmse / 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuJ4HO23zkL4",
        "outputId": "67104baf-6a64-4b2d-87e6-ca1db0d91c4d"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE(in kB): 388.672138803499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Second Approach \n",
        "With the results we got from the last part we know that we add all of the DNS responses into a list and try to solve the problem of caching dnses."
      ],
      "metadata": {
        "id": "f5qvQRKrTbj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "google_videos_ips = []\n",
        "for i in range(22):\n",
        "  # Iterating through files\n",
        "  filename = f\"Capture_v2_{i}.csv\"\n",
        "  data = pd.read_csv(filename)\n",
        "  dns_data = data[data['Protocol']=='DNS']\n",
        "  dns = dns_data[dns_data['Info'].apply(lambda x: 'googlevideo' in x and 'response' in x)]\n",
        "  ips = dns.Address.values\n",
        "  google_videos_ips += [ip for ip in ips]\n",
        "google_videos_ips = list(set(google_videos_ips))\n"
      ],
      "metadata": {
        "id": "vaYBmEfU0TIT"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_videos_ips = list(set(google_videos_ips))\n",
        "google_videos_ips"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zhx1tq3m2DX7",
        "outputId": "7a6f75fd-eceb-48ac-ff85-450e3aa30167"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['173.194.187.136',\n",
              " '74.125.99.108',\n",
              " '74.125.163.138',\n",
              " '173.194.160.219',\n",
              " '74.125.111.106',\n",
              " '74.125.162.40',\n",
              " '74.125.162.39',\n",
              " '74.125.4.230',\n",
              " '173.194.182.230',\n",
              " '74.125.153.7',\n",
              " '74.125.160.38',\n",
              " '91.81.217.141',\n",
              " '74.125.99.170',\n",
              " '173.194.188.136',\n",
              " '74.125.99.91',\n",
              " '91.81.217.140',\n",
              " '173.194.187.71',\n",
              " '74.125.99.137',\n",
              " '74.125.99.72',\n",
              " '173.194.188.72',\n",
              " '74.125.99.168',\n",
              " '74.125.99.106',\n",
              " '74.125.99.105',\n",
              " '74.125.160.202',\n",
              " '74.125.99.166',\n",
              " '74.125.111.102',\n",
              " '74.125.153.59',\n",
              " '74.125.111.105',\n",
              " '173.194.188.105',\n",
              " '74.125.105.10',\n",
              " '173.194.188.230',\n",
              " '209.85.226.38',\n",
              " '173.194.160.200',\n",
              " '74.125.99.169',\n",
              " '173.194.182.138',\n",
              " '74.125.154.138',\n",
              " '173.194.182.135',\n",
              " '74.125.104.103',\n",
              " '74.125.110.102',\n",
              " '172.217.132.137',\n",
              " '74.125.153.11',\n",
              " '74.125.153.24']"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_traffic_v2(data, ips):\n",
        "    # Filtering on either \"Source\" or \"Destination\" IP, get the \n",
        "    # rows of the dataset that contain at least one of the selected IPs\n",
        "    downlink = data[data['Source'].apply(lambda x: x in ips)].dropna(subset=['Length']) \n",
        "\n",
        "    uplink = data[data['Destination'].apply(lambda x: x in ips)].dropna(subset=['Length'])\n",
        "    \n",
        "    return uplink, downlink"
      ],
      "metadata": {
        "id": "yzlZDa752FRx"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joint_df = pd.DataFrame()\n",
        "for i in range(22):\n",
        "  # Iterating through files\n",
        "  filename = f\"Capture_v2_{i}.csv\"\n",
        "  df = pd.read_csv(filename)\n",
        "  uplink, downlink = filter_traffic_v2(df, google_videos_ips)\n",
        "  dom_ul, dom_dl = find_dominant(uplink, downlink)\n",
        "  # Filtering the uplink and downlinks\n",
        "  # 100 bytes for uplink that comes from the paper\n",
        "  # 50 bytes for downlink that comes from the class discussion\n",
        "  dom_ul = timebased_filter(dom_ul, 100, 2, 180)\n",
        "  dom_dl = timebased_filter(dom_dl, 50, 2, 180)\n",
        "  dataset, groundtruth = features_extraction(dom_ul, dom_dl)\n",
        "  joint_dataset = pd.concat([joint_dataset, dataset])\n",
        "  joint_gt = pd.concat([joint_gt, groundtruth])\n",
        "  print(f\"i: {i}, dataset_shape: {dataset.shape[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c08SyJVm3iNg",
        "outputId": "a3d47651-b339-46ac-c946-a202599f708a"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i: 0, dataset_shape: 45\n",
            "i: 1, dataset_shape: 32\n",
            "i: 2, dataset_shape: 35\n",
            "i: 3, dataset_shape: 51\n",
            "i: 4, dataset_shape: 55\n",
            "i: 5, dataset_shape: 58\n",
            "i: 6, dataset_shape: 82\n",
            "i: 7, dataset_shape: 74\n",
            "i: 8, dataset_shape: 23\n",
            "i: 9, dataset_shape: 37\n",
            "i: 10, dataset_shape: 40\n",
            "i: 11, dataset_shape: 42\n",
            "i: 12, dataset_shape: 30\n",
            "i: 13, dataset_shape: 11\n",
            "i: 14, dataset_shape: 11\n",
            "i: 15, dataset_shape: 22\n",
            "i: 16, dataset_shape: 10\n",
            "i: 17, dataset_shape: 21\n",
            "i: 18, dataset_shape: 30\n",
            "i: 19, dataset_shape: 32\n",
            "i: 20, dataset_shape: 30\n",
            "i: 21, dataset_shape: 34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting X and y\n",
        "X = dataset.values\n",
        "y = groundtruth[\"Next_Request_Time\"].values.ravel()\n",
        "\n",
        "mean_rmse = kfold_test(dataset, groundtruth, 5)\n",
        "\n",
        "print('RMSE(in seconds):', mean_rmse)"
      ],
      "metadata": {
        "id": "e3S8qR5n4d_H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "babba880-36f8-4fef-f914-ad91de53191e"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE(in seconds): 3.3952324769473234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your data into X and y\n",
        "X = dataset.values\n",
        "y = groundtruth[\"Next_Response_Vol\"].values.ravel()\n",
        "\n",
        "mean_rmse = kfold_test(dataset, groundtruth, 5)\n",
        "\n",
        "# Since it's in kB we divide it by 1000\n",
        "print('RMSE(in kB):', mean_rmse / 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jgc3vBLolKzL",
        "outputId": "55839068-4f7c-44be-a85b-9d9eec0684a9"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE(in kB): 267.45013416469317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We clearly see that we are finding way better results this way! \n",
        "\n",
        "Hessam Hashemizadeh"
      ],
      "metadata": {
        "id": "HpIIofVYlP7A"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RfMzA9-JlOWL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}